{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ebf90ee-af0d-445d-80c1-97ab076200eb",
   "metadata": {},
   "source": [
    "### Hand Detection Testing with MediaPipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d19527-3f66-4970-91c7-ae0732ce41a4",
   "metadata": {},
   "source": [
    "This notebook implements a script to test the capabilities of MediaPipe Hands, an ML model by Google that marks hand landmarks. There is additional code which uses the landmarks obtained by MediaPipe to create a custom bounding box around a detected hand, with pixel adjustments to create an appropriate buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d211fe6a-0941-44a7-be9a-44de2ec16879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "from google.protobuf.json_format import MessageToDict\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83fa7ec0-40a5-4113-acd4-d173f685d6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpHands = mp.solutions.hands\n",
    "hands = mpHands.Hands(\n",
    "    static_image_mode=False,\n",
    "    model_complexity=1,\n",
    "    min_detection_confidence=0.75,\n",
    "    min_tracking_confidence=0.75,\n",
    "    max_num_hands=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceb46ca7-a9d1-4361-9d09-e05cc952c798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.geeksforgeeks.org/right-and-left-hand-detection-using-python/\n",
    "# https://github.com/google/mediapipe/issues/1390#issuecomment-749333655"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f29400f1-31e8-4677-9941-1d1cb6054080",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "letters = np.array(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
    "'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z'])\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # Read video frame by frame\n",
    "    success, img = cap.read()\n",
    "  \n",
    "    # Flip the image(frame)\n",
    "    img = cv2.flip(img, 1)\n",
    "  \n",
    "    # Convert BGR image to RGB image\n",
    "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "  \n",
    "    # Process the RGB image\n",
    "    results = hands.process(imgRGB)\n",
    "  \n",
    "    # If hands are present in image(frame)\n",
    "    if results.multi_hand_landmarks:\n",
    "  \n",
    "        for hand_landmark in results.multi_hand_landmarks:\n",
    "            x = [landmark.x for landmark in hand_landmark.landmark]\n",
    "            y = [landmark.y for landmark in hand_landmark.landmark]  \n",
    "            \n",
    "            img_height = img.shape[0]\n",
    "            img_width = img.shape[1]\n",
    "            xmin, xmax, ymin, ymax = int(min(x)*img_width), int(max(x)*img_width), int(min(y)*img_height), int(max(y)*img_height)\n",
    "            xmin, ymin, xmax, ymax = xmin-23, ymin-23, xmax+23, ymax+23\n",
    "\n",
    "            center = np.array([np.median(x)*img_width, np.median(y)*img_height]).astype('int32')\n",
    "            cv2.circle(img, tuple(center), 10, (36, 238, 42), 1)  #for checking the center \n",
    "            cv2.rectangle(img=img, pt1=(xmin, ymin), pt2=(xmax, ymax), color=(36, 238, 42), thickness=2)\n",
    "\n",
    "              \n",
    "    # Display Video and when 'q' is entered, destroy the window\n",
    "    cv2.imshow('Image', img)\n",
    "    if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f6ce1e0-4ce0-462d-9937-0926387a8bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25912893"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_array[0][3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
